# Retrieval Model Configuration
# Configuration for retrieval models used in inference

# Paths configuration
paths:
  data_root: "./data"
  model_root: "./model"
  output_root: "./experiments/results"
  cache_root: "./data/preprocessed"

# Retriever Configuration
retriever:

  # Qwen3-Embedding Configuration
  qwen:
    model_path: "model/raw/qwen3"  # Default: use base model
    top_k: 5
    chunk_size: 512
    overlap: 12
    score_threshold: 0.0

  # BGE-M3 Multi-Vector Configuration
  bge:
    model_path: "model/raw/bge-m3"
    top_k: 5
    chunk_size: 512
    overlap: 12
    # Multi-vector weights
    dense_weight: 1.0      # Dense embedding weight
    sparse_weight: 0.3     # Sparse (lexical) weight
    colbert_weight: 1.0    # ColBERT weight
    # Reranker
    use_reranker: false
    reranker_model: "model/raw/bge-reranker"
    rerank_top_k: 5

  # Jina Embeddings v3 Configuration
  jina:
    model_path: "model/raw/jina-v3"
    top_k: 5
    chunk_size: 512
    overlap: 12
    trust_remote_code: true

  # Stella v5 Configuration
  stella:
    model_path: "model/raw/stella-400m"
    top_k: 5
    chunk_size: 512
    overlap: 12
    query_prompt_name: "s2p_query"  # Stella-specific prompt

  # No Retrieval Baseline (LLM only, no chunking/retrieval)
  no_retrieval:
    # No model needed - passes full context directly to LLM
    top_k: 0
    chunk_size: 0
    overlap: 0
